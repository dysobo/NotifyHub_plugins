import hmac
import hashlib
from typing import Any, Dict, List, Optional, Tuple
import asyncio
import json
import logging
import base64
import time
import os
from datetime import datetime
from pathlib import Path

import aiohttp
import aiofiles
from openai import AsyncOpenAI
from fastapi import APIRouter, Header, HTTPException, Request, Query
from fastapi.responses import FileResponse, PlainTextResponse

from notifyhub.plugins.utils import get_plugin_config
from notifyhub.controller.server import server
from notifyhub.plugins.common import after_setup

# ä¼ä¸šå¾®ä¿¡å·¥å…·
from .wxwork_crypto import WXBizMsgCrypt, parse_wxwork_message
from .wxwork_api import WXWorkAPI


PLUGIN_ID = "aihub_chat"

# Media storage configuration
MEDIA_DIR = Path("data/plugins/aihub_chat/media")
MEDIA_DIR.mkdir(parents=True, exist_ok=True)

# Conversation history storage (ç®€å•å†…å­˜å­˜å‚¨ï¼Œå¯æ‰©å±•ä¸ºæ•°æ®åº“)
conversation_history: Dict[str, List[Dict[str, str]]] = {}
MAX_HISTORY_LENGTH = 10  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯

# æ¶ˆæ¯å»é‡ï¼šå­˜å‚¨å·²å¤„ç†çš„æ¶ˆæ¯ID
processed_message_ids: set = set()
MAX_PROCESSED_IDS = 1000  # æœ€å¤šä¿å­˜1000ä¸ªæ¶ˆæ¯ID

aihub_chat_router = APIRouter(prefix=f"/{PLUGIN_ID}", tags=[PLUGIN_ID])
logger = logging.getLogger(__name__)


@aihub_chat_router.get("/ping")
async def ping() -> Dict[str, Any]:
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"ok": True, "plugin": PLUGIN_ID, "version": "0.0.2"}


@aihub_chat_router.get("/status")
async def status() -> Dict[str, Any]:
    """çŠ¶æ€æ£€æŸ¥ç«¯ç‚¹"""
    config = _get_config()
    return {
        "plugin": PLUGIN_ID,
        "version": "0.0.2",
        "timestamp": datetime.now().isoformat(),
        "config": {
            "api_base_url": config.get('api_base_url'),
            "has_api_key": bool(config.get('api_key')),
            "chat_model": config.get('chat_model'),
            "image_model": config.get('image_model'),
            "enable_web_search": config.get('enable_web_search', False),
            "enable_tts": config.get('enable_tts', False),
            "enable_stt": config.get('enable_stt', False),
            "enable_wxwork": config.get('enable_wxwork', False),
        },
        "statistics": {
            "active_conversations": len(conversation_history),
            "media_files": len(list(MEDIA_DIR.glob("*")))
        }
    }


@aihub_chat_router.post("/test")
async def test_send() -> Dict[str, Any]:
    """æµ‹è¯•ç«¯ç‚¹ - æµ‹è¯•ä¼ä¸šå¾®ä¿¡è¿æ¥"""
    config = _get_config()
    
    if not config.get('enable_wxwork', False):
        raise HTTPException(status_code=400, detail='ä¼ä¸šå¾®ä¿¡æœªå¯ç”¨ï¼Œè¯·å…ˆåœ¨é…ç½®ä¸­å¯ç”¨')
    
    # æµ‹è¯•ä¼ä¸šå¾®ä¿¡ API è¿æ¥
    wx_api = _get_wxwork_api()
    if not wx_api:
        raise HTTPException(status_code=400, detail='ä¼ä¸šå¾®ä¿¡é…ç½®ä¸å®Œæ•´')
    
    try:
        # è·å– access_token æµ‹è¯•è¿æ¥
        token = await wx_api.get_access_token()
        if token:
            return {
                "ok": True, 
                "message": "âœ… ä¼ä¸šå¾®ä¿¡è¿æ¥æ­£å¸¸",
                "details": {
                    "api_base": config.get('wxwork_api_base'),
                    "corp_id": config.get('wxwork_corp_id'),
                    "agent_id": config.get('wxwork_agent_id'),
                    "has_token": True,
                    "token_preview": token[:20] + "..." if len(token) > 20 else token
                }
            }
        else:
            raise HTTPException(status_code=500, detail='æ— æ³•è·å– access_tokenï¼Œè¯·æ£€æŸ¥é…ç½®')
    except Exception as e:
        logger.error("WXWork test failed: %s", e)
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")


@aihub_chat_router.get("/debug/upload-test")
async def test_upload() -> Dict[str, Any]:
    """æµ‹è¯•åª’ä½“ä¸Šä¼ åŠŸèƒ½"""
    config = _get_config()
    
    if not config.get('enable_wxwork', False):
        raise HTTPException(status_code=400, detail='ä¼ä¸šå¾®ä¿¡æœªå¯ç”¨')
    
    wx_api = _get_wxwork_api()
    if not wx_api:
        raise HTTPException(status_code=400, detail='ä¼ä¸šå¾®ä¿¡é…ç½®ä¸å®Œæ•´')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ–‡ä»¶
    test_files = list(MEDIA_DIR.glob("tts_*.mp3"))
    if not test_files:
        return {
            "ok": False,
            "message": "æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•è¯­éŸ³æ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨ /tts å‘½ä»¤ç”Ÿæˆè¯­éŸ³"
        }
    
    # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶æµ‹è¯•ä¸Šä¼ 
    test_file = str(test_files[-1])
    
    try:
        logger.info(f"Testing upload with file: {test_file}")
        media_id = await wx_api.upload_media(test_file, "voice")
        
        if media_id:
            return {
                "ok": True,
                "message": "âœ… ä¸Šä¼ æµ‹è¯•æˆåŠŸ",
                "details": {
                    "file": test_file,
                    "media_id": media_id,
                    "file_size": os.path.getsize(test_file)
                }
            }
        else:
            return {
                "ok": False,
                "message": "âŒ ä¸Šä¼ å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯"
            }
    except Exception as e:
        logger.error(f"Upload test failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@aihub_chat_router.get("/media/{filename}")
async def get_media(filename: str):
    """æä¾›åª’ä½“æ–‡ä»¶è®¿é—®"""
    file_path = MEDIA_DIR / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="Media file not found")
    return FileResponse(file_path)


@aihub_chat_router.get("/wxwork")
@aihub_chat_router.post("/wxwork")
async def wxwork_webhook(
    request: Request,
    msg_signature: str = Query(None),
    timestamp: str = Query(None),
    nonce: str = Query(None),
    echostr: str = Query(None)
) -> Any:
    """ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯æ¥æ”¶ç«¯ç‚¹"""
    config = _get_config()
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ä¸šå¾®ä¿¡
    if not config.get('enable_wxwork', False):
        raise HTTPException(status_code=400, detail="WXWork integration not enabled")
    
    # è·å–é…ç½®
    token = config.get('wxwork_token', '')
    encoding_aes_key = config.get('wxwork_encoding_aes_key', '')
    corp_id = config.get('wxwork_corp_id', '')
    
    if not all([token, encoding_aes_key, corp_id]):
        raise HTTPException(status_code=400, detail="WXWork configuration incomplete")
    
    # åˆå§‹åŒ–åŠ å¯†å·¥å…·
    crypto = WXBizMsgCrypt(token, encoding_aes_key, corp_id)
    
    # GET è¯·æ±‚ - URL éªŒè¯
    if request.method == "GET":
        if echostr:
            decrypted = crypto.verify_url(msg_signature, timestamp, nonce, echostr)
            if decrypted:
                logger.info("WXWork URL verification successful")
                return PlainTextResponse(content=decrypted)
            else:
                raise HTTPException(status_code=403, detail="Verification failed")
        else:
            raise HTTPException(status_code=400, detail="Missing echostr parameter")
    
    # POST è¯·æ±‚ - æ¥æ”¶æ¶ˆæ¯
    try:
        body = await request.body()
        xml_data = body.decode('utf-8')
        
        # è§£å¯†æ¶ˆæ¯
        msg_dict = crypto.decrypt_msg(msg_signature, timestamp, nonce, xml_data)
        
        if not msg_dict:
            raise HTTPException(status_code=400, detail="Decryption failed")
        
        logger.info(f"Received WXWork message: {json.dumps(msg_dict, ensure_ascii=False)}")
        
        # å¤„ç†æ¶ˆæ¯
        await _handle_wxwork_message(msg_dict)
        
        # ä¼ä¸šå¾®ä¿¡è¦æ±‚è¿”å› "success"
        return PlainTextResponse(content="success")
        
    except Exception as e:
        logger.error(f"Error processing WXWork message: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


async def _handle_wxwork_message(msg_dict: Dict[str, Any]) -> None:
    """å¤„ç†ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯"""
    msg_type = msg_dict.get('MsgType', 'text')
    user_id = msg_dict.get('FromUserName', 'unknown')
    msg_id = msg_dict.get('MsgId', '')
    
    # è·³è¿‡äº‹ä»¶ç±»å‹çš„æ¶ˆæ¯ï¼ˆsubscribeã€unsubscribe ç­‰ï¼‰
    if msg_type == 'event':
        event_type = msg_dict.get('Event', '')
        logger.info(f"Received event: {event_type} from {user_id}, skipping")
        return
    
    # æ¶ˆæ¯å»é‡ï¼šæ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
    if msg_id and msg_id in processed_message_ids:
        logger.info(f"Message {msg_id} already processed, skipping")
        return
    
    # è®°å½•æ¶ˆæ¯ID
    if msg_id:
        processed_message_ids.add(msg_id)
        # æ§åˆ¶é›†åˆå¤§å°
        if len(processed_message_ids) > MAX_PROCESSED_IDS:
            # ç§»é™¤æœ€æ—©çš„ä¸€åŠ
            to_remove = list(processed_message_ids)[:MAX_PROCESSED_IDS // 2]
            for mid in to_remove:
                processed_message_ids.discard(mid)
    
    # è·å–æˆ–åˆ›å»ºå¯¹è¯å†å²
    if user_id not in conversation_history:
        conversation_history[user_id] = []
    
    try:
        if msg_type == 'text':
            # æ–‡æœ¬æ¶ˆæ¯
            content = msg_dict.get('Content', '')
            logger.info(f"Processing text message from {user_id}: {content}")
            await _handle_text_message(user_id, content, msg_dict, use_wxwork=True)
        elif msg_type == 'image':
            # å›¾ç‰‡æ¶ˆæ¯
            media_id = msg_dict.get('MediaId', '') or msg_dict.get('PicUrl', '')
            logger.info(f"Processing image message from {user_id}, MediaId: {media_id}")
            await _handle_wxwork_image_message(user_id, media_id, msg_dict)
        elif msg_type == 'voice':
            # è¯­éŸ³æ¶ˆæ¯
            media_id = msg_dict.get('MediaId', '')
            logger.info(f"Processing voice message from {user_id}, MediaId: {media_id}")
            await _handle_wxwork_voice_message(user_id, media_id, msg_dict)
        else:
            logger.warning(f"Unsupported WXWork message type: {msg_type}, Full message: {msg_dict}")
            
    except Exception as e:
        logger.error(f"Error handling WXWork message: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™ï¼š{str(e)}")




async def _handle_text_message(user_id: str, content: str, original_data: Dict, use_wxwork: bool = True, from_voice: bool = False) -> None:
    """å¤„ç†æ–‡æœ¬æ¶ˆæ¯"""
    if not content.strip():
        return
    
    # è½¬æ¢ä¸ºå°å†™è¿›è¡Œå‘½ä»¤åŒ¹é…ï¼ˆæ”¯æŒå¤§å°å†™ä¸æ•æ„Ÿï¼‰
    content_lower = content.lower()
    
    # æ£€æŸ¥ç‰¹æ®Šå‘½ä»¤ï¼ˆæ”¯æŒå¤§å°å†™ï¼‰
    if content_lower.startswith('/draw ') or content_lower.startswith('/ç”»å›¾ '):
        # å›¾ç‰‡ç”Ÿæˆå‘½ä»¤
        prompt = content.split(' ', 1)[1] if ' ' in content else ''
        if prompt:
            await _generate_image(user_id, prompt, from_voice=from_voice)
        else:
            await _send_wxwork_response(user_id, "è¯·æä¾›å›¾ç‰‡æè¿°ï¼Œä¾‹å¦‚ï¼š/draw ä¸€åªå¯çˆ±çš„çŒ«å’ª")
        return
    
    # æ™ºèƒ½è¯†åˆ«ç»˜ç”»æ„å›¾ï¼ˆé€‚ç”¨äºè¯­éŸ³è¾“å…¥ï¼‰
    is_draw = _is_draw_intent(content)
    logger.info(f"Draw intent check: '{content}' -> {is_draw}")
    
    if is_draw:
        # æå–ç»˜ç”»æè¿°
        prompt = _extract_draw_prompt(content)
        logger.info(f"Extracted draw prompt: '{prompt}'")
        
        if prompt and len(prompt) > 1:  # è‡³å°‘æœ‰2ä¸ªå­—ç¬¦
            logger.info(f"Generating image for: '{prompt}'")
            await _generate_image(user_id, prompt, from_voice=from_voice, original_text=content)
        else:
            logger.warning(f"Draw prompt is empty or too short: '{prompt}'")
            await _send_wxwork_response(user_id, "è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³ç”»ä»€ä¹ˆï¼Œä¾‹å¦‚ï¼šç”»ä¸€åªå¯çˆ±çš„çŒ«å’ª")
        return
    
    # æ™ºèƒ½è¯†åˆ«è¯­éŸ³åˆæˆæ„å›¾
    if _is_tts_intent(content):
        # æå–è¦è½¬æ¢çš„æ–‡æœ¬
        text_to_speak = _extract_tts_text(content)
        if text_to_speak:
            await _text_to_speech(user_id, text_to_speak, from_voice=from_voice, original_text=content)
        else:
            await _send_wxwork_response(user_id, "è¯·å‘Šè¯‰æˆ‘è¦è½¬æ¢ä»€ä¹ˆæ–‡å­—ï¼Œä¾‹å¦‚ï¼šæœ—è¯» ä½ å¥½ä¸–ç•Œ")
        return
    
    if content_lower.startswith('/search ') or content_lower.startswith('/æœç´¢ '):
        # Web æœç´¢å‘½ä»¤
        query = content.split(' ', 1)[1] if ' ' in content else ''
        if query:
            await _web_search(user_id, query)
        else:
            await _send_wxwork_response(user_id, "è¯·æä¾›æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š/search Pythonæ•™ç¨‹")
        return
    
    if content_lower.startswith('/tts ') or content_lower.startswith('/è¯­éŸ³ '):
        # TTS å‘½ä»¤
        text = content.split(' ', 1)[1] if ' ' in content else ''
        if text:
            await _text_to_speech(user_id, text, from_voice=from_voice)
        else:
            await _send_wxwork_response(user_id, "è¯·æä¾›è¦è½¬æ¢çš„æ–‡å­—ï¼Œä¾‹å¦‚ï¼š/tts ä½ å¥½ä¸–ç•Œ")
        return
    
    if content_lower.strip() in ['/clear', '/æ¸…ç©º', '/reset', '/é‡ç½®']:
        # æ¸…ç©ºå¯¹è¯å†å²
        conversation_history[user_id] = []
        await _send_wxwork_response(user_id, "âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
        return
    
    # æ™®é€šå¯¹è¯
    await _chat(user_id, content, from_voice=from_voice)


async def _chat(user_id: str, user_message: str, from_voice: bool = False) -> None:
    """AI å¯¹è¯"""
    config = _get_config()
    
    try:
        client = _get_openai_client()
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        conversation_history[user_id].append({
            "role": "user",
            "content": user_message
        })
        
        messages = _build_messages(user_id)
        
        response = await client.chat.completions.create(
            model=config.get('chat_model', 'gpt-4o-mini'),
            messages=messages,
            max_tokens=int(config.get('max_tokens', 2000)),
            temperature=float(config.get('temperature', 0.7))
        )
        
        ai_response = response.choices[0].message.content
        
        # æ·»åŠ  AI å›å¤åˆ°å†å²
        conversation_history[user_id].append({
            "role": "assistant",
            "content": ai_response
        })
        
        # æ§åˆ¶å†å²é•¿åº¦
        _trim_conversation_history(user_id)
        
        # å¦‚æœæ˜¯è¯­éŸ³è¾“å…¥ï¼Œæ˜¾ç¤ºè¯†åˆ«çš„æ–‡æœ¬
        if from_voice:
            await _send_wxwork_response(user_id, f"ğŸ¤ {user_message}\n\n{ai_response}")
        else:
            await _send_wxwork_response(user_id, ai_response)
        
    except Exception as e:
        logger.error(f"Chat failed: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ å¯¹è¯å¤±è´¥ï¼š{str(e)}")


async def _generate_image(user_id: str, prompt: str, from_voice: bool = False, original_text: str = None) -> None:
    """ç”Ÿæˆå›¾ç‰‡"""
    config = _get_config()
    
    try:
        client = _get_openai_client()
        
        response = await client.images.generate(
            model=config.get('image_model', 'dall-e-3'),
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        
        image_url = response.data[0].url
        
        # ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡
        local_image = await _download_media(image_url, "generated_image")
        if local_image:
            # ä¼ä¸šå¾®ä¿¡ï¼šä¸Šä¼ å›¾ç‰‡å¹¶å‘é€
            wx_api = _get_wxwork_api()
            if wx_api:
                file_path = str(MEDIA_DIR / local_image)
                media_id = await wx_api.upload_media(file_path, "image")
                if media_id:
                    # å¦‚æœæ˜¯è¯­éŸ³è¾“å…¥ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬
                    if from_voice and original_text:
                        await _send_wxwork_response(user_id, f"ğŸ¤ {original_text}\n\nğŸ¨ å›¾ç‰‡ç”Ÿæˆå®Œæˆ", media_id=media_id, media_type="image")
                    else:
                        await _send_wxwork_response(user_id, f"ğŸ¨ å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼š\n{prompt}", media_id=media_id, media_type="image")
                else:
                    public_url = _generate_media_url(local_image)
                    await _send_wxwork_response(user_id, f"ğŸ¨ å›¾ç‰‡å·²ç”Ÿæˆï¼š\n{public_url}")
            else:
                await _send_wxwork_response(user_id, "âŒ ä¼ä¸šå¾®ä¿¡ API æœªé…ç½®")
        else:
            await _send_wxwork_response(user_id, f"ğŸ¨ å›¾ç‰‡å·²ç”Ÿæˆï¼š\n{image_url}")
        
    except Exception as e:
        logger.error(f"Image generation failed: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")


async def _web_search(user_id: str, query: str) -> None:
    """æ™ºèƒ½æœç´¢ - ä½¿ç”¨ AI çŸ¥è¯†åº“å›ç­”é—®é¢˜"""
    config = _get_config()
    
    if not config.get('enable_web_search', False):
        await _send_wxwork_response(user_id, "âŒ æ™ºèƒ½æœç´¢åŠŸèƒ½æœªå¯ç”¨")
        return
    
    try:
        # ä½¿ç”¨ AIHubMix çš„è”ç½‘æœç´¢åŠŸèƒ½ï¼ˆTavilyï¼‰
        # åœ¨æ¨¡å‹åç§°ååŠ  :surfing åç¼€ï¼Œå¯ç”¨å®æ—¶æœç´¢
        client = _get_openai_client()
        
        base_model = config.get('chat_model', 'gpt-4o-mini')
        search_model = f"{base_model}:surfing"  # æ·»åŠ  :surfing åç¼€
        
        logger.info(f"Web search using model: {search_model}, query: {query}")
        
        messages = [
            {
                "role": "system", 
                "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥è®¿é—®äº’è”ç½‘æœç´¢æœ€æ–°ä¿¡æ¯ã€‚è¯·æ ¹æ®æœç´¢ç»“æœæä¾›å‡†ç¡®çš„å›ç­”ï¼Œå°½é‡åŒ…å«å…·ä½“æ•°æ®å’Œä¿¡æ¯æ¥æºé“¾æ¥ã€‚ç”¨ä¸­æ–‡å›ç­”ã€‚"
            },
            {
                "role": "user", 
                "content": query
            }
        ]
        
        response = await client.chat.completions.create(
            model=search_model,  # ä½¿ç”¨å¸¦ :surfing åç¼€çš„æ¨¡å‹
            messages=messages,
            max_tokens=int(config.get('max_tokens', 2000)),
            temperature=float(config.get('temperature', 0.7))
        )
        
        search_result = response.choices[0].message.content
        
        # è®°å½•è¯¦ç»†æ—¥å¿—ç”¨äºè°ƒè¯•
        logger.info(f"Search response model: {response.model}")
        logger.info(f"Search response usage: {response.usage}")
        logger.info(f"Search result preview: {search_result[:200]}...")
        
        # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦æœ‰æœç´¢æ ‡è®°
        if hasattr(response, 'model') and response.model:
            logger.info(f"Actual model used: {response.model}")
        
        await _send_wxwork_response(user_id, f"ğŸ” æœç´¢ç»“æœï¼š\n\n{search_result}\n\nâš ï¸ æ³¨ï¼šæœç´¢åŠŸèƒ½æ­£åœ¨æµ‹è¯•ä¸­ï¼Œç»“æœå¯èƒ½ä¸å‡†ç¡®")
        
    except Exception as e:
        logger.error(f"Search failed: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ æœç´¢å¤±è´¥ï¼š{str(e)}")


async def _text_to_speech(user_id: str, text: str, from_voice: bool = False, original_text: str = None) -> None:
    """æ–‡æœ¬è½¬è¯­éŸ³"""
    config = _get_config()
    
    if not config.get('enable_tts', False):
        await _send_wxwork_response(user_id, "âŒ TTS åŠŸèƒ½æœªå¯ç”¨")
        return
    
    try:
        client = _get_openai_client()
        
        # ç”Ÿæˆè¯­éŸ³ï¼ˆAsyncOpenAI çš„æ–¹æ³•å·²ç»æ˜¯å¼‚æ­¥çš„ï¼‰
        response = await client.audio.speech.create(
            model="tts-1",
            voice=config.get('tts_voice', 'nova'),
            input=text
        )
        
        # ä¿å­˜è¯­éŸ³æ–‡ä»¶
        timestamp = int(time.time())
        filename = f"tts_{timestamp}.mp3"
        file_path = MEDIA_DIR / filename
        
        # stream_to_file æ˜¯åŒæ­¥æ–¹æ³•ï¼Œéœ€è¦ç”¨ to_thread
        await asyncio.to_thread(response.stream_to_file, str(file_path))
        
        # ç¡®ä¿æ–‡ä»¶å·²å®Œå…¨å†™å…¥
        if not file_path.exists():
            logger.error(f"TTS file not found after save: {file_path}")
            await _send_wxwork_response(user_id, "âŒ è¯­éŸ³æ–‡ä»¶ä¿å­˜å¤±è´¥")
            return
        
        file_size = os.path.getsize(file_path)
        logger.info(f"TTS file saved: {file_path}, size: {file_size} bytes")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆä¼ä¸šå¾®ä¿¡é™åˆ¶ 2MBï¼‰
        if file_size > 2 * 1024 * 1024:
            logger.error(f"TTS file too large: {file_size} bytes")
            await _send_wxwork_response(user_id, "âŒ è¯­éŸ³æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡2MBé™åˆ¶ï¼‰")
            return
        
        if file_size == 0:
            logger.error("TTS file is empty")
            await _send_wxwork_response(user_id, "âŒ è¯­éŸ³æ–‡ä»¶ä¸ºç©º")
            return
        
        # ä¼ä¸šå¾®ä¿¡ï¼šä¸Šä¼ è¯­éŸ³å¹¶å‘é€
        # æ³¨æ„ï¼šä¼ä¸šå¾®ä¿¡æ”¯æŒ AMR æ ¼å¼ï¼ŒMP3 å¯èƒ½éœ€è¦è½¬æ¢
        wx_api = _get_wxwork_api()
        if wx_api:
            # å°è¯•è½¬æ¢ MP3 ä¸º AMRï¼ˆä¼ä¸šå¾®ä¿¡æ¨èæ ¼å¼ï¼‰
            amr_filename = f"tts_{timestamp}.amr"
            amr_file_path = MEDIA_DIR / amr_filename
            
            # å°è¯•è½¬æ¢ä¸º AMR
            converted = await _convert_mp3_to_amr(str(file_path), str(amr_file_path))
            
            if converted and amr_file_path.exists():
                # ä½¿ç”¨ AMR æ–‡ä»¶ä¸Šä¼ 
                upload_file = str(amr_file_path)
                logger.info(f"Using AMR format: {upload_file}")
            else:
                # AMR è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸ MP3 æ–‡ä»¶
                upload_file = str(file_path)
                logger.info(f"AMR conversion failed, using MP3: {upload_file}")
            
            logger.info(f"Uploading TTS voice file: {upload_file} ({os.path.getsize(upload_file)} bytes)")
            media_id = await wx_api.upload_media(upload_file, "voice")
            
            if media_id:
                logger.info(f"TTS voice uploaded successfully, media_id: {media_id}")
                # ç›´æ¥å‘é€è¯­éŸ³æ¶ˆæ¯
                await _send_wxwork_response(user_id, f"ğŸ”Š {text}", media_id=media_id, media_type="voice")
            else:
                # ä¸Šä¼ å¤±è´¥ï¼Œå‘é€å¸¦é“¾æ¥çš„æ–‡æœ¬æ¶ˆæ¯
                logger.warning(f"TTS voice upload failed, sending link instead")
                voice_url = _generate_media_url(filename)
                await _send_wxwork_response(user_id, f"ğŸ”Š è¯­éŸ³å·²ç”Ÿæˆï¼ˆç‚¹å‡»é“¾æ¥æ’­æ”¾ï¼‰ï¼š\n{voice_url}")
        else:
            logger.error("WXWork API not configured for TTS")
            await _send_wxwork_response(user_id, "âŒ ä¼ä¸šå¾®ä¿¡ API æœªé…ç½®")
        
    except Exception as e:
        logger.error(f"TTS failed: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ è¯­éŸ³åˆæˆå¤±è´¥ï¼š{str(e)}")


def _get_config() -> Dict[str, Any]:
    """è·å–æ’ä»¶é…ç½®"""
    return get_plugin_config(PLUGIN_ID) or {}


def _get_openai_client() -> AsyncOpenAI:
    """è·å– OpenAI å®¢æˆ·ç«¯ï¼ˆå…¼å®¹ AIHubMixï¼‰"""
    config = _get_config()
    
    api_key = config.get('api_key')
    if not api_key:
        raise ValueError("API Key not configured")
    
    base_url = config.get('api_base_url', 'https://aihubmix.com/v1')
    
    return AsyncOpenAI(
        api_key=api_key,
        base_url=base_url
    )


def _build_messages(user_id: str) -> List[Dict[str, Any]]:
    """æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºå’Œå¯¹è¯å†å²ï¼‰"""
    config = _get_config()
    system_prompt = config.get('system_prompt', 'ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹')
    
    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(conversation_history.get(user_id, []))
    
    return messages


def _trim_conversation_history(user_id: str) -> None:
    """æ§åˆ¶å¯¹è¯å†å²é•¿åº¦"""
    if user_id in conversation_history:
        if len(conversation_history[user_id]) > MAX_HISTORY_LENGTH * 2:
            # ä¿ç•™æœ€è¿‘çš„å¯¹è¯
            conversation_history[user_id] = conversation_history[user_id][-(MAX_HISTORY_LENGTH * 2):]


def _is_draw_intent(text: str) -> bool:
    """
    æ™ºèƒ½è¯†åˆ«æ˜¯å¦æ˜¯ç»˜ç”»æ„å›¾
    é€‚ç”¨äºè¯­éŸ³è¾“å…¥åœºæ™¯ï¼Œå¦‚"ç”»ä¸€åªçŒ«"ã€"å¸®æˆ‘ç”»å›¾"ç­‰
    """
    text_lower = text.lower().strip()
    
    # ç»˜ç”»å…³é”®è¯åˆ—è¡¨
    draw_keywords = [
        'ç”»', 'ç»˜ç”»', 'ç»˜åˆ¶', 'ç”»ä¸ª', 'ç”»ä¸€', 'ç”»å¼ ',
        'ç”Ÿæˆå›¾', 'ç”Ÿæˆä¸€å¼ ', 'ç”Ÿæˆä¸€å¹…',
        'å¸®æˆ‘ç”»', 'ç»™æˆ‘ç”»', 'æˆ‘æƒ³ç”»',
        'åˆ›ä½œ', 'è®¾è®¡', 'åˆ¶ä½œå›¾'
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»˜ç”»å…³é”®è¯
    for keyword in draw_keywords:
        if keyword in text_lower:
            # æ’é™¤ä¸€äº›è¯¯è¯†åˆ«çš„æƒ…å†µ
            exclude_keywords = ['ç”»é¢', 'ç”»è´¨', 'åŠ¨ç”»', 'æ¼«ç”»ä¹¦', 'çœ‹ç”»', 'æŒ‚ç”»']
            if not any(ex in text_lower for ex in exclude_keywords):
                return True
    
    return False


def _extract_draw_prompt(text: str) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå–ç»˜ç”»æè¿°
    ä¾‹å¦‚ï¼š"ç”»ä¸€åªå¯çˆ±çš„çŒ«" -> "ä¸€åªå¯çˆ±çš„çŒ«"
    """
    text = text.strip()
    text_lower = text.lower()
    
    # ç§»é™¤å¸¸è§çš„å‰ç¼€ï¼ˆæŒ‰é•¿åº¦æ’åºï¼Œå…ˆåŒ¹é…é•¿çš„ï¼‰
    # ä½¿ç”¨å…ƒç»„ (å°å†™å…³é”®è¯, åŸé•¿åº¦) æ¥åŒ¹é…
    prefixes = [
        'å¸®æˆ‘ç”»ä¸€ä¸ª', 'ç»™æˆ‘ç”»ä¸€ä¸ª', 'å¸®æˆ‘ç”»ä¸€åª', 'ç»™æˆ‘ç”»ä¸€åª',
        'ç”Ÿæˆä¸€å¼ å›¾ç‰‡', 'ç”Ÿæˆä¸€å¹…å›¾ç‰‡',
        'å¸®æˆ‘ç”»', 'ç»™æˆ‘ç”»', 'æˆ‘æƒ³ç”»',
        'ç”Ÿæˆå›¾ç‰‡', 'ç”Ÿæˆä¸€å¼ ', 'ç”Ÿæˆä¸€å¹…',
        'ç”»ä¸€ä¸ª', 'ç”»ä¸€åª', 'ç”»ä¸€å¼ ', 'ç”»ä¸€å¹…',
        'ç»˜åˆ¶ä¸€ä¸ª', 'ç»˜åˆ¶ä¸€åª',
        'ç»˜åˆ¶', 'ç»˜ç”»', 'åˆ›ä½œ', 'è®¾è®¡',
        'ç”»ä¸ª', 'ç”»'
    ]
    
    for prefix in prefixes:
        if text_lower.startswith(prefix):
            # æ‰¾åˆ°åŒ¹é…çš„å‰ç¼€ï¼Œä»åŸæ–‡æœ¬ä¸­æå–ï¼ˆä¿ç•™å¤§å°å†™ï¼‰
            prompt = text[len(prefix):].strip()
            
            # å¦‚æœæå–çš„å†…å®¹ä¸ä¸ºç©ºä¸”æœ‰æ„ä¹‰ï¼Œè¿”å›
            if prompt and len(prompt) > 0:
                logger.info(f"Extracted draw prompt: '{text}' -> '{prompt}' (removed prefix: '{prefix}')")
                return prompt
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å‰ç¼€ï¼Œè¿”å›åŸæ–‡æœ¬
    logger.warning(f"No prefix matched for: '{text}', using full text as prompt")
    return text


def _is_tts_intent(text: str) -> bool:
    """
    æ™ºèƒ½è¯†åˆ«æ˜¯å¦æ˜¯è¯­éŸ³åˆæˆæ„å›¾
    é€‚ç”¨äºè¯­éŸ³è¾“å…¥åœºæ™¯ï¼Œå¦‚"æœ—è¯»è¿™æ®µæ–‡å­—"ã€"è½¬æˆè¯­éŸ³"ç­‰
    """
    text_lower = text.lower().strip()
    
    # è¯­éŸ³åˆæˆå…³é”®è¯
    tts_keywords = [
        'æœ—è¯»', 'è¯»å‡º', 'è¯­éŸ³', 'å¿µå‡º',
        'è½¬æˆè¯­éŸ³', 'è½¬ä¸ºè¯­éŸ³', 'è½¬æ¢æˆè¯­éŸ³',
        'è¯´å‡º', 'æ’­æ”¾', 'è¯»ä¸€ä¸‹'
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯­éŸ³åˆæˆå…³é”®è¯
    for keyword in tts_keywords:
        if keyword in text_lower:
            return True
    
    return False


def _extract_tts_text(text: str) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå–è¦è½¬æ¢ä¸ºè¯­éŸ³çš„å†…å®¹
    ä¾‹å¦‚ï¼š"æœ—è¯» ä½ å¥½ä¸–ç•Œ" -> "ä½ å¥½ä¸–ç•Œ"
    """
    text = text.strip()
    
    # ç§»é™¤å¸¸è§çš„å‰ç¼€
    prefixes = [
        'å¸®æˆ‘æœ—è¯»', 'ç»™æˆ‘æœ—è¯»', 'æœ—è¯»ä¸€ä¸‹',
        'è½¬æˆè¯­éŸ³', 'è½¬ä¸ºè¯­éŸ³', 'è½¬æ¢æˆè¯­éŸ³',
        'å¸®æˆ‘è¯»', 'ç»™æˆ‘è¯»',
        'æœ—è¯»', 'è¯»å‡º', 'å¿µå‡º', 'è¯´å‡º', 'æ’­æ”¾', 'è¯»ä¸€ä¸‹'
    ]
    
    text_lower = text.lower()
    for prefix in prefixes:
        if text_lower.startswith(prefix):
            # æå–åé¢çš„å†…å®¹
            result = text[len(prefix):].strip()
            if result:
                return result
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å‰ç¼€ï¼Œè¿”å›åŸæ–‡æœ¬
    return text


async def _download_media(url: str, media_type: str = "image") -> Optional[str]:
    """ä¸‹è½½åª’ä½“æ–‡ä»¶"""
    try:
        if not url.startswith(('http://', 'https://')):
            logger.warning(f"Invalid media URL format: {url}")
            return None
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                if response.status != 200:
                    logger.warning(f"Failed to download media: {url}, status: {response.status}")
                    return None
                
                timestamp = int(time.time())
                content_type = response.headers.get('content-type', '')
                
                # ç¡®å®šæ–‡ä»¶æ‰©å±•å
                if media_type == "image" or "image" in content_type:
                    if 'jpeg' in content_type or 'jpg' in content_type:
                        ext = '.jpg'
                    elif 'png' in content_type:
                        ext = '.png'
                    elif 'gif' in content_type:
                        ext = '.gif'
                    elif 'webp' in content_type:
                        ext = '.webp'
                    else:
                        ext = '.jpg'
                elif media_type == "audio" or "audio" in content_type:
                    if 'mp3' in content_type:
                        ext = '.mp3'
                    elif 'wav' in content_type:
                        ext = '.wav'
                    elif 'ogg' in content_type:
                        ext = '.ogg'
                    else:
                        ext = '.mp3'
                else:
                    ext = '.bin'
                
                filename = f"{media_type}_{timestamp}{ext}"
                file_path = MEDIA_DIR / filename
                
                async with aiofiles.open(file_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(8192):
                        await f.write(chunk)
                
                logger.info(f"Downloaded media: {url} -> {filename}")
                return filename
    
    except Exception as e:
        logger.error(f"Failed to download media {url}: {e}", exc_info=True)
        return None


def _generate_media_url(filename: str) -> str:
    """ç”Ÿæˆåª’ä½“æ–‡ä»¶çš„å…¬ç½‘ URL"""
    site_url = server.site_url or "http://localhost"
    return f"{site_url}/api/plugins/{PLUGIN_ID}/media/{filename}"


async def _convert_audio_format(input_path: str, output_path: str) -> bool:
    """
    è½¬æ¢éŸ³é¢‘æ ¼å¼ï¼ˆAMR -> MP3ï¼Œç”¨äº STTï¼‰
    :param input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
    :param output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    :return: æ˜¯å¦è½¬æ¢æˆåŠŸ
    """
    try:
        from pydub import AudioSegment
        
        logger.info(f"Converting audio: {input_path} -> {output_path}")
        
        # åœ¨çº¿ç¨‹ä¸­æ‰§è¡ŒéŸ³é¢‘è½¬æ¢ï¼ˆé¿å…é˜»å¡ï¼‰
        def convert():
            # å°è¯•è¯»å– AMR æ ¼å¼
            try:
                audio = AudioSegment.from_file(input_path, format="amr")
            except:
                # å¦‚æœ AMR å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
                audio = AudioSegment.from_file(input_path)
            
            # å¯¼å‡ºä¸º MP3
            audio.export(output_path, format="mp3", bitrate="64k")
            return True
        
        result = await asyncio.to_thread(convert)
        logger.info(f"Audio conversion successful: {output_path}")
        return result
        
    except Exception as e:
        logger.error(f"Audio conversion failed: {e}", exc_info=True)
        return False


async def _convert_mp3_to_amr(input_path: str, output_path: str) -> bool:
    """
    è½¬æ¢ MP3 ä¸º AMR æ ¼å¼ï¼ˆç”¨äºä¼ä¸šå¾®ä¿¡è¯­éŸ³æ¶ˆæ¯ï¼‰
    :param input_path: MP3 æ–‡ä»¶è·¯å¾„
    :param output_path: AMR æ–‡ä»¶è·¯å¾„
    :return: æ˜¯å¦è½¬æ¢æˆåŠŸ
    """
    logger.info(f"Converting MP3 to AMR: {input_path} -> {output_path}")
    
    # æ–¹æ³• 1ï¼šä½¿ç”¨ ffmpeg å‘½ä»¤è¡Œï¼ˆæ›´å¯é ï¼‰
    try:
        import subprocess
        
        def convert_with_ffmpeg():
            # ä¼ä¸šå¾®ä¿¡ AMR è¦æ±‚ï¼š
            # - ç¼–ç ï¼šamr_nb (AMR-NB, çª„å¸¦)
            # - é‡‡æ ·ç‡ï¼š8000 Hz
            # - å•å£°é“
            # - æ¯”ç‰¹ç‡ï¼š12.2k
            cmd = [
                'ffmpeg',
                '-i', input_path,
                '-ar', '8000',          # é‡‡æ ·ç‡ 8kHz
                '-ac', '1',             # å•å£°é“
                '-ab', '12.2k',         # æ¯”ç‰¹ç‡
                '-acodec', 'libopencore_amrnb',  # AMR-NB ç¼–ç å™¨
                '-y',                   # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
                output_path
            ]
            
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30
            )
            
            return result.returncode == 0
        
        success = await asyncio.to_thread(convert_with_ffmpeg)
        
        if success and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            file_size = os.path.getsize(output_path)
            logger.info(f"MP3->AMR conversion successful (ffmpeg): {output_path} ({file_size} bytes)")
            return True
        else:
            logger.warning("ffmpeg conversion failed, trying pydub...")
            
    except Exception as e:
        logger.warning(f"ffmpeg conversion failed: {e}, trying pydub...")
    
    # æ–¹æ³• 2ï¼šä½¿ç”¨ pydubï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    try:
        from pydub import AudioSegment
        
        def convert_with_pydub():
            # è¯»å– MP3
            audio = AudioSegment.from_file(input_path, format="mp3")
            
            # ä¼ä¸šå¾®ä¿¡ AMR è¦æ±‚
            audio = audio.set_frame_rate(8000).set_channels(1)
            
            # å¯¼å‡ºä¸º AMR
            audio.export(output_path, format="amr", bitrate="12.2k")
            return True
        
        result = await asyncio.to_thread(convert_with_pydub)
        
        if result and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            file_size = os.path.getsize(output_path)
            logger.info(f"MP3->AMR conversion successful (pydub): {output_path} ({file_size} bytes)")
            return True
        
    except Exception as e:
        logger.error(f"pydub conversion also failed: {e}", exc_info=True)
    
    logger.error("All MP3->AMR conversion methods failed")
    return False


def _get_wxwork_api() -> Optional[WXWorkAPI]:
    """è·å–ä¼ä¸šå¾®ä¿¡ API å®¢æˆ·ç«¯"""
    config = _get_config()
    
    if not config.get('enable_wxwork', False):
        return None
    
    api_base = config.get('wxwork_api_base', 'https://qyapi.weixin.qq.com')
    corp_id = config.get('wxwork_corp_id', '')
    secret = config.get('wxwork_secret', '')
    agent_id_str = config.get('wxwork_agent_id', '0')
    
    try:
        agent_id = int(agent_id_str)
    except:
        agent_id = 0
    
    if not all([corp_id, secret, agent_id]):
        logger.warning("WXWork API configuration incomplete")
        return None
    
    return WXWorkAPI(api_base, corp_id, secret, agent_id)


async def _send_wxwork_response(user_id: str, content: str, media_id: str = None, media_type: str = None) -> None:
    """é€šè¿‡ä¼ä¸šå¾®ä¿¡å‘é€å“åº”æ¶ˆæ¯"""
    wx_api = _get_wxwork_api()
    if not wx_api:
        logger.error("WXWork API not available")
        return
    
    try:
        if media_id and media_type == "image":
            # å‘é€å›¾ç‰‡
            success = await wx_api.send_image_message(user_id, media_id)
        elif media_id and media_type == "voice":
            # å‘é€è¯­éŸ³
            success = await wx_api.send_voice_message(user_id, media_id)
        elif len(content) < 2048:
            # å‘é€æ–‡æœ¬ï¼ˆä¼ä¸šå¾®ä¿¡æ–‡æœ¬æ¶ˆæ¯é•¿åº¦é™åˆ¶ï¼‰
            success = await wx_api.send_text_message(user_id, content)
        else:
            # è¶…é•¿å†…å®¹åˆ†æ®µå‘é€
            chunks = [content[i:i+2000] for i in range(0, len(content), 2000)]
            for chunk in chunks:
                success = await wx_api.send_text_message(user_id, chunk)
                await asyncio.sleep(0.1)  # é¿å…é¢‘ç‡é™åˆ¶
        
        if not success:
            logger.error(f"Failed to send WXWork message to {user_id}")
    except Exception as e:
        logger.error(f"Error sending WXWork response: {e}", exc_info=True)


async def _handle_wxwork_image_message(user_id: str, media_id: str, original_data: Dict) -> None:
    """å¤„ç†ä¼ä¸šå¾®ä¿¡å›¾ç‰‡æ¶ˆæ¯"""
    config = _get_config()
    wx_api = _get_wxwork_api()
    
    if not wx_api:
        await _send_wxwork_response(user_id, "âŒ ä¼ä¸šå¾®ä¿¡ API æœªé…ç½®")
        return
    
    # ä¸‹è½½å›¾ç‰‡
    image_data = await wx_api.get_media(media_id)
    if not image_data:
        await _send_wxwork_response(user_id, "âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥")
        return
    
    # ä¿å­˜å›¾ç‰‡
    timestamp = int(time.time())
    filename = f"wxwork_image_{timestamp}.jpg"
    file_path = MEDIA_DIR / filename
    
    async with aiofiles.open(file_path, 'wb') as f:
        await f.write(image_data)
    
    # è½¬ base64 ç”¨äº AI åˆ†æ
    image_base64 = base64.b64encode(image_data).decode('utf-8')
    
    # ä½¿ç”¨è§†è§‰æ¨¡å‹åˆ†æå›¾ç‰‡
    try:
        client = _get_openai_client()
        
        conversation_history[user_id].append({
            "role": "user",
            "content": [
                {"type": "text", "text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                }
            ]
        })
        
        messages = _build_messages(user_id)
        
        response = await client.chat.completions.create(
            model=config.get('chat_model', 'gpt-4o-mini'),
            messages=messages,
            max_tokens=int(config.get('max_tokens', 2000)),
            temperature=float(config.get('temperature', 0.7))
        )
        
        ai_response = response.choices[0].message.content
        
        conversation_history[user_id].append({
            "role": "assistant",
            "content": ai_response
        })
        
        _trim_conversation_history(user_id)
        
        await _send_wxwork_response(user_id, f"ğŸ–¼ï¸ å›¾ç‰‡åˆ†æï¼š\n\n{ai_response}")
        
    except Exception as e:
        logger.error(f"WXWork image analysis failed: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼š{str(e)}")


async def _handle_wxwork_voice_message(user_id: str, media_id: str, original_data: Dict) -> None:
    """å¤„ç†ä¼ä¸šå¾®ä¿¡è¯­éŸ³æ¶ˆæ¯"""
    config = _get_config()
    
    if not config.get('enable_stt', False):
        await _send_wxwork_response(user_id, "âŒ è¯­éŸ³è¯†åˆ«åŠŸèƒ½æœªå¯ç”¨")
        return
    
    wx_api = _get_wxwork_api()
    if not wx_api:
        await _send_wxwork_response(user_id, "âŒ ä¼ä¸šå¾®ä¿¡ API æœªé…ç½®")
        return
    
    # ä¸‹è½½è¯­éŸ³
    voice_data = await wx_api.get_media(media_id)
    if not voice_data:
        await _send_wxwork_response(user_id, "âŒ è¯­éŸ³ä¸‹è½½å¤±è´¥")
        return
    
    # ä¿å­˜åŸå§‹è¯­éŸ³æ–‡ä»¶ï¼ˆAMR æ ¼å¼ï¼‰
    timestamp = int(time.time())
    amr_filename = f"wxwork_voice_{timestamp}.amr"
    amr_file_path = MEDIA_DIR / amr_filename
    
    async with aiofiles.open(amr_file_path, 'wb') as f:
        await f.write(voice_data)
    
    logger.info(f"Saved AMR file: {amr_file_path}, size: {len(voice_data)} bytes")
    
    # STT è½¬æ–‡æœ¬
    try:
        # è½¬æ¢ AMR ä¸º MP3ï¼ˆWhisper æ”¯æŒçš„æ ¼å¼ï¼‰
        mp3_filename = f"wxwork_voice_{timestamp}.mp3"
        mp3_file_path = MEDIA_DIR / mp3_filename
        
        # ä½¿ç”¨ pydub è½¬æ¢éŸ³é¢‘æ ¼å¼
        success = await _convert_audio_format(str(amr_file_path), str(mp3_file_path))
        
        if not success:
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶ï¼ˆæŸäº›æƒ…å†µä¸‹å¯èƒ½ä¸æ˜¯çœŸçš„ AMRï¼‰
            logger.warning("Audio conversion failed, trying original file")
            mp3_file_path = amr_file_path
        
        client = _get_openai_client()
        
        # AsyncOpenAI çš„æ–¹æ³•å·²ç»æ˜¯å¼‚æ­¥çš„ï¼Œç›´æ¥ await
        with open(mp3_file_path, 'rb') as audio_file:
            transcription = await client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        
        text = transcription.text
        logger.info(f"STT result: {text}")
        
        # é‡è¦ï¼šå°†è¯†åˆ«çš„æ–‡æœ¬äº¤ç»™ _handle_text_message å¤„ç†
        # è¿™æ ·å¯ä»¥è§¦å‘æ™ºèƒ½æ„å›¾è¯†åˆ«ï¼ˆç»˜ç”»ã€TTS ç­‰ï¼‰
        # æ ‡è®° from_voice=Trueï¼Œç”¨äºæ˜¾ç¤ºè¯†åˆ«æ–‡æœ¬
        await _handle_text_message(user_id, text, original_data, use_wxwork=True, from_voice=True)
        
    except Exception as e:
        logger.error(f"WXWork STT failed: {e}", exc_info=True)
        await _send_wxwork_response(user_id, f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š{str(e)}")


@after_setup(plugin_id=PLUGIN_ID, desc="åˆå§‹åŒ– AIHub Chat æ’ä»¶")
def init_plugin() -> None:
    """æ’ä»¶åˆå§‹åŒ–"""
    logger.info(f"{PLUGIN_ID} plugin initialized")
    logger.info(f"Media directory: {MEDIA_DIR}")
    
    config = _get_config()
    if config.get('api_key'):
        logger.info(f"AIHubMix API configured with model: {config.get('chat_model')}")
    else:
        logger.warning(f"{PLUGIN_ID}: API Key not configured!")
    
    if config.get('enable_wxwork', False):
        logger.info("WXWork integration enabled")
    else:
        logger.info("WXWork integration disabled")

